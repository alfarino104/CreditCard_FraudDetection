{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T11:35:13.853932Z","iopub.execute_input":"2023-12-01T11:35:13.854351Z","iopub.status.idle":"2023-12-01T11:35:14.202945Z","shell.execute_reply.started":"2023-12-01T11:35:13.854323Z","shell.execute_reply":"2023-12-01T11:35:14.201532Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/creditcardfraud/creditcard.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Import the dataset**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:14.204552Z","iopub.execute_input":"2023-12-01T11:35:14.205005Z","iopub.status.idle":"2023-12-01T11:35:18.069255Z","shell.execute_reply.started":"2023-12-01T11:35:14.204975Z","shell.execute_reply":"2023-12-01T11:35:18.068170Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"            Time         V1         V2        V3        V4        V5  \\\n0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n...          ...        ...        ...       ...       ...       ...   \n284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n\n              V6        V7        V8        V9  ...       V21       V22  \\\n0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n...          ...       ...       ...       ...  ...       ...       ...   \n284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n\n             V23       V24       V25       V26       V27       V28  Amount  \\\n0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n...          ...       ...       ...       ...       ...       ...     ...   \n284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n\n        Class  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  \n...       ...  \n284802      0  \n284803      0  \n284804      0  \n284805      0  \n284806      0  \n\n[284807 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>284802</th>\n      <td>172786.0</td>\n      <td>-11.881118</td>\n      <td>10.071785</td>\n      <td>-9.834783</td>\n      <td>-2.066656</td>\n      <td>-5.364473</td>\n      <td>-2.606837</td>\n      <td>-4.918215</td>\n      <td>7.305334</td>\n      <td>1.914428</td>\n      <td>...</td>\n      <td>0.213454</td>\n      <td>0.111864</td>\n      <td>1.014480</td>\n      <td>-0.509348</td>\n      <td>1.436807</td>\n      <td>0.250034</td>\n      <td>0.943651</td>\n      <td>0.823731</td>\n      <td>0.77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284803</th>\n      <td>172787.0</td>\n      <td>-0.732789</td>\n      <td>-0.055080</td>\n      <td>2.035030</td>\n      <td>-0.738589</td>\n      <td>0.868229</td>\n      <td>1.058415</td>\n      <td>0.024330</td>\n      <td>0.294869</td>\n      <td>0.584800</td>\n      <td>...</td>\n      <td>0.214205</td>\n      <td>0.924384</td>\n      <td>0.012463</td>\n      <td>-1.016226</td>\n      <td>-0.606624</td>\n      <td>-0.395255</td>\n      <td>0.068472</td>\n      <td>-0.053527</td>\n      <td>24.79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284804</th>\n      <td>172788.0</td>\n      <td>1.919565</td>\n      <td>-0.301254</td>\n      <td>-3.249640</td>\n      <td>-0.557828</td>\n      <td>2.630515</td>\n      <td>3.031260</td>\n      <td>-0.296827</td>\n      <td>0.708417</td>\n      <td>0.432454</td>\n      <td>...</td>\n      <td>0.232045</td>\n      <td>0.578229</td>\n      <td>-0.037501</td>\n      <td>0.640134</td>\n      <td>0.265745</td>\n      <td>-0.087371</td>\n      <td>0.004455</td>\n      <td>-0.026561</td>\n      <td>67.88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284805</th>\n      <td>172788.0</td>\n      <td>-0.240440</td>\n      <td>0.530483</td>\n      <td>0.702510</td>\n      <td>0.689799</td>\n      <td>-0.377961</td>\n      <td>0.623708</td>\n      <td>-0.686180</td>\n      <td>0.679145</td>\n      <td>0.392087</td>\n      <td>...</td>\n      <td>0.265245</td>\n      <td>0.800049</td>\n      <td>-0.163298</td>\n      <td>0.123205</td>\n      <td>-0.569159</td>\n      <td>0.546668</td>\n      <td>0.108821</td>\n      <td>0.104533</td>\n      <td>10.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284806</th>\n      <td>172792.0</td>\n      <td>-0.533413</td>\n      <td>-0.189733</td>\n      <td>0.703337</td>\n      <td>-0.506271</td>\n      <td>-0.012546</td>\n      <td>-0.649617</td>\n      <td>1.577006</td>\n      <td>-0.414650</td>\n      <td>0.486180</td>\n      <td>...</td>\n      <td>0.261057</td>\n      <td>0.643078</td>\n      <td>0.376777</td>\n      <td>0.008797</td>\n      <td>-0.473649</td>\n      <td>-0.818267</td>\n      <td>-0.002415</td>\n      <td>0.013649</td>\n      <td>217.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>284807 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe() #to see the detail of the data","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:18.070326Z","iopub.execute_input":"2023-12-01T11:35:18.071244Z","iopub.status.idle":"2023-12-01T11:35:18.433856Z","shell.execute_reply.started":"2023-12-01T11:35:18.071194Z","shell.execute_reply":"2023-12-01T11:35:18.432498Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.168375e-15</td>\n      <td>3.416908e-16</td>\n      <td>-1.379537e-15</td>\n      <td>2.074095e-15</td>\n      <td>9.604066e-16</td>\n      <td>1.487313e-15</td>\n      <td>-5.556467e-16</td>\n      <td>1.213481e-16</td>\n      <td>-2.406331e-15</td>\n      <td>...</td>\n      <td>1.654067e-16</td>\n      <td>-3.568593e-16</td>\n      <td>2.578648e-16</td>\n      <td>4.473266e-15</td>\n      <td>5.340915e-16</td>\n      <td>1.683437e-15</td>\n      <td>-3.660091e-16</td>\n      <td>-1.227390e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Scaling or Standardize the data**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\n#copying the dataframe \ndf1 = df.copy()\ndf1['Amount'] = RobustScaler().fit_transform(df1['Amount'].to_numpy().reshape(-1,1))\ntime = df1['Time']\ndf1['Time']= (time - time.min()) / (time.max() - time.min())\ndf1","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:18.436685Z","iopub.execute_input":"2023-12-01T11:35:18.437076Z","iopub.status.idle":"2023-12-01T11:35:18.996690Z","shell.execute_reply.started":"2023-12-01T11:35:18.437040Z","shell.execute_reply":"2023-12-01T11:35:18.995771Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            Time         V1         V2        V3        V4        V5  \\\n0       0.000000  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n1       0.000000   1.191857   0.266151  0.166480  0.448154  0.060018   \n2       0.000006  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n3       0.000006  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n4       0.000012  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n...          ...        ...        ...       ...       ...       ...   \n284802  0.999965 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n284803  0.999971  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n284804  0.999977   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n284805  0.999977  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n284806  1.000000  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n\n              V6        V7        V8        V9  ...       V21       V22  \\\n0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n...          ...       ...       ...       ...  ...       ...       ...   \n284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n\n             V23       V24       V25       V26       V27       V28    Amount  \\\n0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  1.783274   \n1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.269825   \n2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721   \n3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291   \n4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.670579   \n...          ...       ...       ...       ...       ...       ...       ...   \n284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.296653   \n284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.038986   \n284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.641096   \n284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.167680   \n284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  2.724796   \n\n        Class  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  \n...       ...  \n284802      0  \n284803      0  \n284804      0  \n284805      0  \n284806      0  \n\n[284807 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>1.783274</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>-0.269825</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000006</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>4.983721</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000006</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>1.418291</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000012</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>0.670579</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>284802</th>\n      <td>0.999965</td>\n      <td>-11.881118</td>\n      <td>10.071785</td>\n      <td>-9.834783</td>\n      <td>-2.066656</td>\n      <td>-5.364473</td>\n      <td>-2.606837</td>\n      <td>-4.918215</td>\n      <td>7.305334</td>\n      <td>1.914428</td>\n      <td>...</td>\n      <td>0.213454</td>\n      <td>0.111864</td>\n      <td>1.014480</td>\n      <td>-0.509348</td>\n      <td>1.436807</td>\n      <td>0.250034</td>\n      <td>0.943651</td>\n      <td>0.823731</td>\n      <td>-0.296653</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284803</th>\n      <td>0.999971</td>\n      <td>-0.732789</td>\n      <td>-0.055080</td>\n      <td>2.035030</td>\n      <td>-0.738589</td>\n      <td>0.868229</td>\n      <td>1.058415</td>\n      <td>0.024330</td>\n      <td>0.294869</td>\n      <td>0.584800</td>\n      <td>...</td>\n      <td>0.214205</td>\n      <td>0.924384</td>\n      <td>0.012463</td>\n      <td>-1.016226</td>\n      <td>-0.606624</td>\n      <td>-0.395255</td>\n      <td>0.068472</td>\n      <td>-0.053527</td>\n      <td>0.038986</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284804</th>\n      <td>0.999977</td>\n      <td>1.919565</td>\n      <td>-0.301254</td>\n      <td>-3.249640</td>\n      <td>-0.557828</td>\n      <td>2.630515</td>\n      <td>3.031260</td>\n      <td>-0.296827</td>\n      <td>0.708417</td>\n      <td>0.432454</td>\n      <td>...</td>\n      <td>0.232045</td>\n      <td>0.578229</td>\n      <td>-0.037501</td>\n      <td>0.640134</td>\n      <td>0.265745</td>\n      <td>-0.087371</td>\n      <td>0.004455</td>\n      <td>-0.026561</td>\n      <td>0.641096</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284805</th>\n      <td>0.999977</td>\n      <td>-0.240440</td>\n      <td>0.530483</td>\n      <td>0.702510</td>\n      <td>0.689799</td>\n      <td>-0.377961</td>\n      <td>0.623708</td>\n      <td>-0.686180</td>\n      <td>0.679145</td>\n      <td>0.392087</td>\n      <td>...</td>\n      <td>0.265245</td>\n      <td>0.800049</td>\n      <td>-0.163298</td>\n      <td>0.123205</td>\n      <td>-0.569159</td>\n      <td>0.546668</td>\n      <td>0.108821</td>\n      <td>0.104533</td>\n      <td>-0.167680</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284806</th>\n      <td>1.000000</td>\n      <td>-0.533413</td>\n      <td>-0.189733</td>\n      <td>0.703337</td>\n      <td>-0.506271</td>\n      <td>-0.012546</td>\n      <td>-0.649617</td>\n      <td>1.577006</td>\n      <td>-0.414650</td>\n      <td>0.486180</td>\n      <td>...</td>\n      <td>0.261057</td>\n      <td>0.643078</td>\n      <td>0.376777</td>\n      <td>0.008797</td>\n      <td>-0.473649</td>\n      <td>-0.818267</td>\n      <td>-0.002415</td>\n      <td>0.013649</td>\n      <td>2.724796</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>284807 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Shuffle the data**","metadata":{}},{"cell_type":"code","source":"df1 = df1.sample(frac= 1, random_state= 4)\ndf1","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:18.997809Z","iopub.execute_input":"2023-12-01T11:35:18.998071Z","iopub.status.idle":"2023-12-01T11:35:19.136873Z","shell.execute_reply.started":"2023-12-01T11:35:18.998048Z","shell.execute_reply":"2023-12-01T11:35:19.135244Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            Time        V1        V2        V3        V4        V5        V6  \\\n135406  0.470161  0.999672 -0.034679  0.446984  1.374760 -0.272838  0.033625   \n137826  0.476567 -0.844413  1.032424  1.090921 -0.671593 -0.006061 -0.621923   \n70830   0.312717 -0.474271  1.027526  1.546229 -0.082036  0.180465 -0.407305   \n194993  0.757292 -1.619583 -0.460686  0.219034 -0.418723  0.933105 -0.477342   \n87575   0.357337 -1.159349  0.816687  1.743063 -0.724069 -0.398590 -0.796834   \n...          ...       ...       ...       ...       ...       ...       ...   \n107578  0.408046  1.329792 -0.532095  0.410993 -0.557842 -1.134187 -1.030980   \n94601   0.375874 -4.886561  2.942698  0.260037 -0.229327 -2.422474 -0.161059   \n115144  0.426889  1.211935 -1.052726  1.179067 -0.510623 -1.841176 -0.316907   \n129384  0.457573  1.560825 -1.325706 -0.770189 -2.497505  0.693174  3.454604   \n120705  0.439442  1.248423 -0.845492  1.042291 -0.729424 -1.444453 -0.063721   \n\n              V7        V8        V9  ...       V21       V22       V23  \\\n135406  0.025702  0.118362  0.052625  ... -0.006060  0.042805 -0.095535   \n137826  0.322604  0.513167 -0.705964  ... -0.080023 -0.535090  0.005324   \n70830   0.695010  0.025371 -0.522539  ... -0.186400 -0.415345  0.014862   \n194993  0.902804 -0.120123  0.138692  ... -0.009905  0.886662  0.620723   \n87575   0.275232  0.405158 -0.238336  ... -0.215970 -0.746148 -0.141145   \n...          ...       ...       ...  ...       ...       ...       ...   \n107578 -0.395008 -0.251508 -0.881992  ... -0.466074 -0.940960  0.112772   \n94601  -1.069271  1.758930  1.604665  ... -0.321738 -0.006026  0.008159   \n115144 -1.287568  0.212432 -0.152247  ...  0.383081  0.970212 -0.112781   \n129384 -1.834426  0.856034 -1.736648  ... -0.115227 -0.057266 -0.033700   \n120705 -1.234688  0.247365 -0.564367  ...  0.473486  1.253617 -0.062444   \n\n             V24       V25       V26       V27       V28    Amount  Class  \n135406  0.227518  0.575778 -0.347302  0.024111  0.016893  0.586879      0  \n137826 -0.042269 -0.453002 -0.127804 -0.057711  0.053107 -0.294977      0  \n70830   0.076099 -0.236694  0.097987  0.284462  0.120016 -0.181793      0  \n194993 -0.317571  0.048672  0.617770  0.383019  0.054503  0.754279      0  \n87575   0.423557  0.225527  0.749267 -0.169812 -0.036058 -0.138336      0  \n...          ...       ...       ...       ...       ...       ...    ...  \n107578  0.412913  0.092228  0.899739 -0.059533  0.017364  0.248725      0  \n94601   0.541297  0.565461  0.216912 -0.783219 -0.828006  0.266192      0  \n115144  0.549760  0.332893 -0.076174  0.028321  0.022106  0.461119      0  \n129384  0.997058  0.503315 -0.087907  0.055294  0.020042 -0.184448      0  \n120705  0.260420  0.267337 -0.048974  0.043132  0.015095  0.041780      0  \n\n[284807 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>135406</th>\n      <td>0.470161</td>\n      <td>0.999672</td>\n      <td>-0.034679</td>\n      <td>0.446984</td>\n      <td>1.374760</td>\n      <td>-0.272838</td>\n      <td>0.033625</td>\n      <td>0.025702</td>\n      <td>0.118362</td>\n      <td>0.052625</td>\n      <td>...</td>\n      <td>-0.006060</td>\n      <td>0.042805</td>\n      <td>-0.095535</td>\n      <td>0.227518</td>\n      <td>0.575778</td>\n      <td>-0.347302</td>\n      <td>0.024111</td>\n      <td>0.016893</td>\n      <td>0.586879</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>137826</th>\n      <td>0.476567</td>\n      <td>-0.844413</td>\n      <td>1.032424</td>\n      <td>1.090921</td>\n      <td>-0.671593</td>\n      <td>-0.006061</td>\n      <td>-0.621923</td>\n      <td>0.322604</td>\n      <td>0.513167</td>\n      <td>-0.705964</td>\n      <td>...</td>\n      <td>-0.080023</td>\n      <td>-0.535090</td>\n      <td>0.005324</td>\n      <td>-0.042269</td>\n      <td>-0.453002</td>\n      <td>-0.127804</td>\n      <td>-0.057711</td>\n      <td>0.053107</td>\n      <td>-0.294977</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70830</th>\n      <td>0.312717</td>\n      <td>-0.474271</td>\n      <td>1.027526</td>\n      <td>1.546229</td>\n      <td>-0.082036</td>\n      <td>0.180465</td>\n      <td>-0.407305</td>\n      <td>0.695010</td>\n      <td>0.025371</td>\n      <td>-0.522539</td>\n      <td>...</td>\n      <td>-0.186400</td>\n      <td>-0.415345</td>\n      <td>0.014862</td>\n      <td>0.076099</td>\n      <td>-0.236694</td>\n      <td>0.097987</td>\n      <td>0.284462</td>\n      <td>0.120016</td>\n      <td>-0.181793</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>194993</th>\n      <td>0.757292</td>\n      <td>-1.619583</td>\n      <td>-0.460686</td>\n      <td>0.219034</td>\n      <td>-0.418723</td>\n      <td>0.933105</td>\n      <td>-0.477342</td>\n      <td>0.902804</td>\n      <td>-0.120123</td>\n      <td>0.138692</td>\n      <td>...</td>\n      <td>-0.009905</td>\n      <td>0.886662</td>\n      <td>0.620723</td>\n      <td>-0.317571</td>\n      <td>0.048672</td>\n      <td>0.617770</td>\n      <td>0.383019</td>\n      <td>0.054503</td>\n      <td>0.754279</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87575</th>\n      <td>0.357337</td>\n      <td>-1.159349</td>\n      <td>0.816687</td>\n      <td>1.743063</td>\n      <td>-0.724069</td>\n      <td>-0.398590</td>\n      <td>-0.796834</td>\n      <td>0.275232</td>\n      <td>0.405158</td>\n      <td>-0.238336</td>\n      <td>...</td>\n      <td>-0.215970</td>\n      <td>-0.746148</td>\n      <td>-0.141145</td>\n      <td>0.423557</td>\n      <td>0.225527</td>\n      <td>0.749267</td>\n      <td>-0.169812</td>\n      <td>-0.036058</td>\n      <td>-0.138336</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107578</th>\n      <td>0.408046</td>\n      <td>1.329792</td>\n      <td>-0.532095</td>\n      <td>0.410993</td>\n      <td>-0.557842</td>\n      <td>-1.134187</td>\n      <td>-1.030980</td>\n      <td>-0.395008</td>\n      <td>-0.251508</td>\n      <td>-0.881992</td>\n      <td>...</td>\n      <td>-0.466074</td>\n      <td>-0.940960</td>\n      <td>0.112772</td>\n      <td>0.412913</td>\n      <td>0.092228</td>\n      <td>0.899739</td>\n      <td>-0.059533</td>\n      <td>0.017364</td>\n      <td>0.248725</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94601</th>\n      <td>0.375874</td>\n      <td>-4.886561</td>\n      <td>2.942698</td>\n      <td>0.260037</td>\n      <td>-0.229327</td>\n      <td>-2.422474</td>\n      <td>-0.161059</td>\n      <td>-1.069271</td>\n      <td>1.758930</td>\n      <td>1.604665</td>\n      <td>...</td>\n      <td>-0.321738</td>\n      <td>-0.006026</td>\n      <td>0.008159</td>\n      <td>0.541297</td>\n      <td>0.565461</td>\n      <td>0.216912</td>\n      <td>-0.783219</td>\n      <td>-0.828006</td>\n      <td>0.266192</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>115144</th>\n      <td>0.426889</td>\n      <td>1.211935</td>\n      <td>-1.052726</td>\n      <td>1.179067</td>\n      <td>-0.510623</td>\n      <td>-1.841176</td>\n      <td>-0.316907</td>\n      <td>-1.287568</td>\n      <td>0.212432</td>\n      <td>-0.152247</td>\n      <td>...</td>\n      <td>0.383081</td>\n      <td>0.970212</td>\n      <td>-0.112781</td>\n      <td>0.549760</td>\n      <td>0.332893</td>\n      <td>-0.076174</td>\n      <td>0.028321</td>\n      <td>0.022106</td>\n      <td>0.461119</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>129384</th>\n      <td>0.457573</td>\n      <td>1.560825</td>\n      <td>-1.325706</td>\n      <td>-0.770189</td>\n      <td>-2.497505</td>\n      <td>0.693174</td>\n      <td>3.454604</td>\n      <td>-1.834426</td>\n      <td>0.856034</td>\n      <td>-1.736648</td>\n      <td>...</td>\n      <td>-0.115227</td>\n      <td>-0.057266</td>\n      <td>-0.033700</td>\n      <td>0.997058</td>\n      <td>0.503315</td>\n      <td>-0.087907</td>\n      <td>0.055294</td>\n      <td>0.020042</td>\n      <td>-0.184448</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>120705</th>\n      <td>0.439442</td>\n      <td>1.248423</td>\n      <td>-0.845492</td>\n      <td>1.042291</td>\n      <td>-0.729424</td>\n      <td>-1.444453</td>\n      <td>-0.063721</td>\n      <td>-1.234688</td>\n      <td>0.247365</td>\n      <td>-0.564367</td>\n      <td>...</td>\n      <td>0.473486</td>\n      <td>1.253617</td>\n      <td>-0.062444</td>\n      <td>0.260420</td>\n      <td>0.267337</td>\n      <td>-0.048974</td>\n      <td>0.043132</td>\n      <td>0.015095</td>\n      <td>0.041780</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>284807 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Splitting the data for Train, Test, and Validation**","metadata":{}},{"cell_type":"code","source":"train, test, valid = df1[:240000], df1[240000:262000], df1[262000:]\n\n#the detail of the data \ntrain[\"Class\"].value_counts(), test[\"Class\"].value_counts(), valid[\"Class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:19.138473Z","iopub.execute_input":"2023-12-01T11:35:19.138886Z","iopub.status.idle":"2023-12-01T11:35:19.158071Z","shell.execute_reply.started":"2023-12-01T11:35:19.138852Z","shell.execute_reply":"2023-12-01T11:35:19.156655Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(Class\n 0    239576\n 1       424\n Name: count, dtype: int64,\n Class\n 0    21967\n 1       33\n Name: count, dtype: int64,\n Class\n 0    22772\n 1       35\n Name: count, dtype: int64)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Transform the data into numpy array**","metadata":{}},{"cell_type":"code","source":"train_np, test_np, valid_np = train.to_numpy(), test.to_numpy(), valid.to_numpy()\n\n#this is for checking the data\ntrain.shape, test.shape, valid.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:19.159823Z","iopub.execute_input":"2023-12-01T11:35:19.160170Z","iopub.status.idle":"2023-12-01T11:35:19.183388Z","shell.execute_reply.started":"2023-12-01T11:35:19.160141Z","shell.execute_reply":"2023-12-01T11:35:19.182225Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"((240000, 31), (22000, 31), (22807, 31))"},"metadata":{}}]},{"cell_type":"markdown","source":"**Splitting the data for the Training and Target**","metadata":{}},{"cell_type":"code","source":"x_train, y_train = train_np[:, :-1], train_np[:, -1]\nx_test, y_test = test_np[:, :-1], test_np[:, -1]\nx_val, y_val = valid_np[:, :-1], valid_np[:, -1]\n\nx_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:38.937635Z","iopub.execute_input":"2023-12-01T11:35:38.938028Z","iopub.status.idle":"2023-12-01T11:35:38.947096Z","shell.execute_reply.started":"2023-12-01T11:35:38.937995Z","shell.execute_reply":"2023-12-01T11:35:38.946008Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((240000, 30), (240000,), (22000, 30), (22000,), (22807, 30), (22807,))"},"metadata":{}}]},{"cell_type":"markdown","source":"**LOGISTIC REGRESSION**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel= LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:43.284377Z","iopub.execute_input":"2023-12-01T11:35:43.284747Z","iopub.status.idle":"2023-12-01T11:35:45.790691Z","shell.execute_reply.started":"2023-12-01T11:35:43.284704Z","shell.execute_reply":"2023-12-01T11:35:45.790054Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.9991875"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nclass_report= classification_report(y_val, model.predict(x_val), target_names= ['Not Fraud', 'Fraud'])\nprint(class_report)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:48.140517Z","iopub.execute_input":"2023-12-01T11:35:48.140924Z","iopub.status.idle":"2023-12-01T11:35:48.215352Z","shell.execute_reply.started":"2023-12-01T11:35:48.140898Z","shell.execute_reply":"2023-12-01T11:35:48.214635Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n   Not Fraud       1.00      1.00      1.00     22772\n       Fraud       0.81      0.49      0.61        35\n\n    accuracy                           1.00     22807\n   macro avg       0.90      0.74      0.80     22807\nweighted avg       1.00      1.00      1.00     22807\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**SIMPLE NEURAL NETWORK**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import InputLayer, Dense, BatchNormalization \nfrom tensorflow.keras.callbacks import ModelCheckpoint \n\nnn = Sequential()\n#adding the layer\nnn.add(InputLayer((x_train.shape[1],)))\nnn.add(Dense(2, 'relu'))\nnn.add(BatchNormalization())\nnn.add(Dense(1, 'sigmoid'))\n\ncheckpoint= ModelCheckpoint('nn', save_best_only= True)\nnn.compile (optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:35:51.497064Z","iopub.execute_input":"2023-12-01T11:35:51.497441Z","iopub.status.idle":"2023-12-01T11:36:04.818331Z","shell.execute_reply.started":"2023-12-01T11:35:51.497411Z","shell.execute_reply":"2023-12-01T11:36:04.816835Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"nn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:38:11.062942Z","iopub.execute_input":"2023-12-01T11:38:11.063316Z","iopub.status.idle":"2023-12-01T11:38:11.084240Z","shell.execute_reply.started":"2023-12-01T11:38:11.063284Z","shell.execute_reply":"2023-12-01T11:38:11.082654Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 2)                 62        \n                                                                 \n batch_normalization (Batch  (None, 2)                 8         \n Normalization)                                                  \n                                                                 \n dense_1 (Dense)             (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 73 (292.00 Byte)\nTrainable params: 69 (276.00 Byte)\nNon-trainable params: 4 (16.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"nn.fit(x_train, y_train, validation_data= (x_val, y_val), epochs= 5, callbacks= checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:38:18.952884Z","iopub.execute_input":"2023-12-01T11:38:18.953264Z","iopub.status.idle":"2023-12-01T11:39:39.046351Z","shell.execute_reply.started":"2023-12-01T11:38:18.953236Z","shell.execute_reply":"2023-12-01T11:39:39.045016Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/5\n7500/7500 [==============================] - 17s 2ms/step - loss: 0.0496 - accuracy: 0.9896 - val_loss: 0.0126 - val_accuracy: 0.9991\nEpoch 2/5\n7500/7500 [==============================] - 15s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0101 - val_accuracy: 0.9992\nEpoch 3/5\n7500/7500 [==============================] - 16s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9992\nEpoch 4/5\n7500/7500 [==============================] - 16s 2ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0093 - val_accuracy: 0.9992\nEpoch 5/5\n7500/7500 [==============================] - 16s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9992\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7f0d851901c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Predict using simple Neural Network**","metadata":{}},{"cell_type":"code","source":"def nn_predictions (model, x):\n    return (nn.predict(x).flatten() > 0.5).astype(int)\nnn_predictions(nn, x_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:39:51.811235Z","iopub.execute_input":"2023-12-01T11:39:51.811608Z","iopub.status.idle":"2023-12-01T11:39:53.063051Z","shell.execute_reply.started":"2023-12-01T11:39:51.811580Z","shell.execute_reply":"2023-12-01T11:39:53.061599Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"713/713 [==============================] - 1s 1ms/step\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(y_val, nn_predictions(nn, x_val), target_names= ['Not Fraud', 'Fraud']))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:39:55.338822Z","iopub.execute_input":"2023-12-01T11:39:55.339181Z","iopub.status.idle":"2023-12-01T11:39:56.423652Z","shell.execute_reply.started":"2023-12-01T11:39:55.339153Z","shell.execute_reply":"2023-12-01T11:39:56.421885Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"713/713 [==============================] - 1s 1ms/step\n              precision    recall  f1-score   support\n\n   Not Fraud       1.00      1.00      1.00     22772\n       Fraud       0.76      0.71      0.74        35\n\n    accuracy                           1.00     22807\n   macro avg       0.88      0.86      0.87     22807\nweighted avg       1.00      1.00      1.00     22807\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**RANDOM FOREST CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf= RandomForestClassifier(max_depth= 2, n_jobs= -1)\nrf.fit(x_train, y_train)\nprint(classification_report(y_val, rf.predict(x_val), target_names= ['Not Fraud', 'Fraud']))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:39:59.271309Z","iopub.execute_input":"2023-12-01T11:39:59.271679Z","iopub.status.idle":"2023-12-01T11:40:10.555798Z","shell.execute_reply.started":"2023-12-01T11:39:59.271651Z","shell.execute_reply":"2023-12-01T11:40:10.554411Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n   Not Fraud       1.00      1.00      1.00     22772\n       Fraud       0.71      0.43      0.54        35\n\n    accuracy                           1.00     22807\n   macro avg       0.86      0.71      0.77     22807\nweighted avg       1.00      1.00      1.00     22807\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**GRADIENT BOOSTING CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc= GradientBoostingClassifier(n_estimators= 100, learning_rate= 1.0, max_depth= 1, random_state= 1)\ngbc.fit(x_train, y_train)\nprint(classification_report(y_val, gbc.predict(x_val), target_names= ['Not Fraud', 'Fraud']))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:43:32.007749Z","iopub.execute_input":"2023-12-01T11:43:32.008134Z","iopub.status.idle":"2023-12-01T11:45:39.202783Z","shell.execute_reply.started":"2023-12-01T11:43:32.008106Z","shell.execute_reply":"2023-12-01T11:45:39.201628Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n   Not Fraud       1.00      1.00      1.00     22772\n       Fraud       0.62      0.57      0.60        35\n\n    accuracy                           1.00     22807\n   macro avg       0.81      0.79      0.80     22807\nweighted avg       1.00      1.00      1.00     22807\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**LINEAR SUPPORT VECTOR MACHINE**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nsvc= LinearSVC(class_weight= 'balanced')\nsvc.fit(x_train, y_train)\nprint(classification_report(y_val, svc.predict(x_val), target_names= ['Not Fraud', 'Fraud']))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T11:45:43.829284Z","iopub.execute_input":"2023-12-01T11:45:43.829690Z","iopub.status.idle":"2023-12-01T11:47:20.465455Z","shell.execute_reply.started":"2023-12-01T11:45:43.829659Z","shell.execute_reply":"2023-12-01T11:47:20.464764Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n   Not Fraud       1.00      1.00      1.00     22772\n       Fraud       0.75      0.69      0.72        35\n\n    accuracy                           1.00     22807\n   macro avg       0.87      0.84      0.86     22807\nweighted avg       1.00      1.00      1.00     22807\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}